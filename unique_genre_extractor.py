#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä –∏ –∏—Ö –∂–∞–Ω—Ä–æ–≤
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import logging
import json
import sqlite3
from urllib.parse import urljoin

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class UniqueGenreExtractor:
    def __init__(self):
        self.base_url = "https://asst2game.ru"
        self.unique_games = {}  # URL -> title –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        self.found_genres = {}  # title -> genres
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_page(self, url: str) -> str:
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    return await response.text()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
        return ""
    
    def extract_unique_games_from_page(self, html_content: str) -> dict:
        """–ò–∑–≤–ª–µ—á—å –£–ù–ò–ö–ê–õ–¨–ù–´–ï –∏–≥—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            page_games = {}
            
            articles = soup.find_all('article')
            for article in articles:
                link = article.find('a', href=True)
                if link and link.get('href').endswith('.html'):
                    href = link.get('href')
                    full_url = urljoin(self.base_url, href)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ URL
                    if full_url not in self.unique_games:
                        title_elem = article.find('h1') or article.find('h2') or article.find('h3') or link
                        title = title_elem.get_text().strip() if title_elem else ""
                        
                        if title and full_url:
                            page_games[full_url] = title
            
            return page_games
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–≥—Ä: {e}")
            return {}
    
    def extract_genres_from_page(self, html_content: str, url: str) -> list:
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            main_container = soup.select_one('body > section.wrap.cf > section > div > div > article')
            
            if main_container:
                meta_genre = main_container.find('meta', attrs={'itemprop': 'genre'})
                if meta_genre and meta_genre.get('content'):
                    content = meta_genre.get('content').strip()
                    genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                    return genres
            
            # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            meta_genre_any = soup.find('meta', attrs={'itemprop': 'genre'})
            if meta_genre_any and meta_genre_any.get('content'):
                content = meta_genre_any.get('content').strip()
                genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                return genres
            
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∂–∞–Ω—Ä–æ–≤: {e}")
            return []
    
    async def collect_unique_games(self, max_pages: int = 100):
        """–°–æ–±—Ä–∞—Ç—å –£–ù–ò–ö–ê–õ–¨–ù–´–ï –∏–≥—Ä—ã"""
        logger.info(f"üöÄ –°–æ–±–∏—Ä–∞—é –£–ù–ò–ö–ê–õ–¨–ù–´–ï –∏–≥—Ä—ã —Å {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
        
        for page in range(1, max_pages + 1):
            url = f"{self.base_url}/page/{page}/" if page > 1 else self.base_url
            
            html = await self.get_page(url)
            if not html:
                continue
            
            page_games = self.extract_unique_games_from_page(html)
            if not page_games:
                logger.info(f"–ù–æ–≤—ã–µ –∏–≥—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∏–≥—Ä—ã
            new_count = 0
            for game_url, title in page_games.items():
                if game_url not in self.unique_games:
                    self.unique_games[game_url] = title
                    new_count += 1
            
            logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: +{new_count} –Ω–æ–≤—ã—Ö –∏–≥—Ä, –≤—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(self.unique_games)}")
            
            await asyncio.sleep(0.5)
        
        logger.info(f"üéØ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä: {len(self.unique_games)}")
        return len(self.unique_games)
    
    async def extract_genres_for_unique_games(self):
        """–ò–∑–≤–ª–µ—á—å –∂–∞–Ω—Ä—ã –¥–ª—è –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä"""
        logger.info(f"üöÄ –ò–∑–≤–ª–µ–∫–∞—é –∂–∞–Ω—Ä—ã –¥–ª—è {len(self.unique_games)} –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä")
        
        processed = 0
        for i, (game_url, title) in enumerate(self.unique_games.items(), 1):
            logger.info(f"üéÆ [{i}/{len(self.unique_games)}] {title}")
            
            html = await self.get_page(game_url)
            if html:
                genres = self.extract_genres_from_page(html, game_url)
                
                if genres:
                    self.found_genres[title] = genres
                    logger.info(f"‚úÖ {title} -> {genres}")
                    processed += 1
                else:
                    logger.warning(f"‚ùå –ñ–∞–Ω—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {title}")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞
            if i % 5 == 0:
                await asyncio.sleep(1)
        
        logger.info(f"üéâ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä —Å –∂–∞–Ω—Ä–∞–º–∏: {processed}/{len(self.unique_games)}")
        return processed
    
    def display_results(self):
        logger.info("üéØ –ö–û–ù–ö–†–ï–¢–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –£–ù–ò–ö–ê–õ–¨–ù–´–• –ò–ì–†:")
        logger.info("=" * 80)
        
        for title, genres in self.found_genres.items():
            genres_str = ", ".join(genres)
            logger.info(f"üéÆ {title} - {genres_str}")
        
        logger.info("=" * 80)
        logger.info(f"üìä –í—Å–µ–≥–æ –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä —Å –∂–∞–Ω—Ä–∞–º–∏: {len(self.found_genres)}")
    
    def save_results(self, filename: str = "unique_genres.json"):
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.found_genres, f, ensure_ascii=False, indent=2)
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filename}")
    
    def update_bot_database(self):
        """–û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –±–æ—Ç–∞ –£–ù–ò–ö–ê–õ–¨–ù–´–ú–ò –∏–≥—Ä–∞–º–∏"""
        try:
            conn = sqlite3.connect('games.db')
            cursor = conn.cursor()
            
            # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–≥—Ä—ã –≤ –±–∞–∑—É
            added = 0
            for game_url, title in self.unique_games.items():
                try:
                    cursor.execute('''
                        INSERT OR IGNORE INTO games (title, url)
                        VALUES (?, ?)
                    ''', (title, game_url))
                    
                    if cursor.rowcount > 0:
                        added += 1
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è {title}: {e}")
            
            conn.commit()
            logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ –£–ù–ò–ö–ê–õ–¨–ù–´–• –∏–≥—Ä –≤ –ë–î: {added}")
            
            # –¢–µ–ø–µ—Ä—å –æ–±–Ω–æ–≤–ª—è–µ–º –∂–∞–Ω—Ä—ã
            updated = 0
            for title, genres in self.found_genres.items():
                try:
                    genres_json = json.dumps(genres, ensure_ascii=False)
                    cursor.execute('''
                        UPDATE games SET genres = ? WHERE title = ?
                    ''', (genres_json, title))
                    
                    if cursor.rowcount > 0:
                        updated += 1
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∂–∞–Ω—Ä–æ–≤ {title}: {e}")
            
            conn.commit()
            conn.close()
            
            logger.info(f"üóÑÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–æ –∂–∞–Ω—Ä–æ–≤ –≤ –ë–î: {updated}")
            return added, updated
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –ë–î: {e}")
            return 0, 0

async def main():
    logger.info("üöÄ –ó–ê–ü–£–°–ö - –£–ù–ò–ö–ê–õ–¨–ù–´–ï –ò–ì–†–´ –ò –ñ–ê–ù–†–´")
    
    async with UniqueGenreExtractor() as extractor:
        # –®–∞–≥ 1: –°–æ–±—Ä–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–≥—Ä—ã
        unique_count = await extractor.collect_unique_games(max_pages=100)
        
        # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á—å –∂–∞–Ω—Ä—ã –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–≥—Ä
        processed = await extractor.extract_genres_for_unique_games()
        
        # –®–∞–≥ 3: –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        extractor.display_results()
        
        # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
        extractor.save_results()
        
        # –®–∞–≥ 5: –û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –±–æ—Ç–∞
        added, updated = extractor.update_bot_database()
        
        logger.info("üéâ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        logger.info(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–≥—Ä: {unique_count}")
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å –∂–∞–Ω—Ä–∞–º–∏: {processed}")
        logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ë–î: {added}")
        logger.info(f"üóÑÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–æ –∂–∞–Ω—Ä–æ–≤: {updated}")

if __name__ == "__main__":
    asyncio.run(main())
