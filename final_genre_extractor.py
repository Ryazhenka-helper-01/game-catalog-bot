#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–´–ô –°–ö–†–ò–ü–¢ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –í–°–ï 800 –∏–≥—Ä —Å—Ä–∞–∑—É
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import logging
import json
import sqlite3
from urllib.parse import urljoin

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FinalGenreExtractor:
    def __init__(self):
        self.base_url = "https://asst2game.ru"
        self.found_genres = {}
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_page(self, url: str) -> str:
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    return await response.text()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
        return ""
    
    def extract_games_from_page(self, html_content: str) -> list:
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            games = []
            
            articles = soup.find_all('article')
            for article in articles:
                link = article.find('a', href=True)
                if link and link.get('href').endswith('.html'):
                    href = link.get('href')
                    full_url = urljoin(self.base_url, href)
                    
                    title_elem = article.find('h1') or article.find('h2') or article.find('h3') or link
                    title = title_elem.get_text().strip() if title_elem else ""
                    
                    if title and full_url:
                        games.append({'title': title, 'url': full_url})
            
            return games
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–≥—Ä: {e}")
            return []
    
    def extract_genres_from_page(self, html_content: str, url: str) -> list:
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            main_container = soup.select_one('body > section.wrap.cf > section > div > div > article')
            
            if main_container:
                meta_genre = main_container.find('meta', attrs={'itemprop': 'genre'})
                if meta_genre and meta_genre.get('content'):
                    content = meta_genre.get('content').strip()
                    genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                    return genres
            
            # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            meta_genre_any = soup.find('meta', attrs={'itemprop': 'genre'})
            if meta_genre_any and meta_genre_any.get('content'):
                content = meta_genre_any.get('content').strip()
                genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                return genres
            
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∂–∞–Ω—Ä–æ–≤: {e}")
            return []
    
    async def process_all_games(self, max_pages: int = 100):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –í–°–ï –∏–≥—Ä—ã"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –í–°–ï–• –∏–≥—Ä —Å {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
        
        all_games = []
        
        # –®–∞–≥ 1: –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –∏–≥—Ä—ã
        for page in range(1, max_pages + 1):
            url = f"{self.base_url}/page/{page}/" if page > 1 else self.base_url
            
            html = await self.get_page(url)
            if not html:
                continue
            
            games = self.extract_games_from_page(html)
            if not games:
                logger.info(f"–ò–≥—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                break
            
            all_games.extend(games)
            logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: +{len(games)} –∏–≥—Ä, –≤—Å–µ–≥–æ: {len(all_games)}")
            
            await asyncio.sleep(0.5)
        
        logger.info(f"üéØ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –∏–≥—Ä: {len(all_games)}")
        
        # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—É—é –∏–≥—Ä—É
        processed = 0
        for i, game in enumerate(all_games, 1):
            logger.info(f"üéÆ [{i}/{len(all_games)}] {game['title']}")
            
            html = await self.get_page(game['url'])
            if html:
                genres = self.extract_genres_from_page(html, game['url'])
                
                if genres:
                    self.found_genres[game['title']] = genres
                    logger.info(f"‚úÖ {game['title']} -> {genres}")
                    processed += 1
                else:
                    logger.warning(f"‚ùå –ñ–∞–Ω—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {game['title']}")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞
            if i % 10 == 0:
                await asyncio.sleep(2)
        
        logger.info(f"üéâ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–≥—Ä —Å –∂–∞–Ω—Ä–∞–º–∏: {processed}/{len(all_games)}")
        return processed
    
    def display_results(self):
        logger.info("üéØ –ö–û–ù–ö–†–ï–¢–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        logger.info("=" * 80)
        
        for title, genres in self.found_genres.items():
            genres_str = ", ".join(genres)
            logger.info(f"üéÆ {title} - {genres_str}")
        
        logger.info("=" * 80)
        logger.info(f"üìä –í—Å–µ–≥–æ –∏–≥—Ä —Å –∂–∞–Ω—Ä–∞–º–∏: {len(self.found_genres)}")
    
    def save_results(self, filename: str = "all_genres.json"):
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.found_genres, f, ensure_ascii=False, indent=2)
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filename}")
    
    def update_database(self):
        """–û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –±–æ—Ç–∞"""
        try:
            conn = sqlite3.connect('games.db')
            cursor = conn.cursor()
            
            updated = 0
            for title, genres in self.found_genres.items():
                try:
                    genres_json = json.dumps(genres, ensure_ascii=False)
                    cursor.execute('''
                        UPDATE games SET genres = ? WHERE title = ?
                    ''', (genres_json, title))
                    
                    if cursor.rowcount > 0:
                        updated += 1
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è {title}: {e}")
            
            conn.commit()
            conn.close()
            
            logger.info(f"üóÑÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ –ë–î: {updated}")
            return updated
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –ë–î: {e}")
            return 0

async def main():
    logger.info("üöÄ –§–ò–ù–ê–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö - –í–°–ï 800 –ò–ì–†!")
    
    async with FinalGenreExtractor() as extractor:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–≥—Ä—ã
        processed = await extractor.process_all_games(max_pages=100)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        extractor.display_results()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        extractor.save_results()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        extractor.update_database()
        
        logger.info("üéâ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê! –í–°–ï –ñ–ê–ù–†–´ –ò–ó–í–õ–ï–ß–ï–ù–´!")

if __name__ == "__main__":
    asyncio.run(main())
