#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∫–∞–∑–∞ –í–°–ï–• 800 –∏–≥—Ä —Å –∏—Ö –∂–∞–Ω—Ä–∞–º–∏ (–≤–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã)
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import logging
import json
from urllib.parse import urljoin

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AllGamesExtractor:
    def __init__(self):
        self.base_url = "https://asst2game.ru"
        self.all_games_with_genres = []  # –í–°–ï –∏–≥—Ä—ã —Å –∂–∞–Ω—Ä–∞–º–∏
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def get_page(self, url: str) -> str:
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    return await response.text()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
        return ""
    
    def extract_games_from_page(self, html_content: str) -> list:
        """–ò–∑–≤–ª–µ—á—å –í–°–ï –∏–≥—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            games = []
            
            articles = soup.find_all('article')
            for article in articles:
                link = article.find('a', href=True)
                if link and link.get('href').endswith('.html'):
                    href = link.get('href')
                    full_url = urljoin(self.base_url, href)
                    
                    title_elem = article.find('h1') or article.find('h2') or article.find('h3') or link
                    title = title_elem.get_text().strip() if title_elem else ""
                    
                    if title and full_url:
                        games.append({'title': title, 'url': full_url})
            
            return games
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–≥—Ä: {e}")
            return []
    
    def extract_genres_from_page(self, html_content: str, url: str) -> list:
        """–ò–∑–≤–ª–µ—á—å –∂–∞–Ω—Ä—ã –ø–æ –¢–û–ß–ù–û–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –®–∞–≥ 2: –ò—â–µ–º body > section.wrap.cf > section > div > div > article
            main_container = soup.select_one('body > section.wrap.cf > section > div > div > article')
            
            if main_container:
                # –®–∞–≥ 3: –ò—â–µ–º <meta itemprop="genre" content="–∂–∞–Ω—Ä—ã">
                meta_genre = main_container.find('meta', attrs={'itemprop': 'genre'})
                if meta_genre and meta_genre.get('content'):
                    content = meta_genre.get('content').strip()
                    genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                    return genres
            
            # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            meta_genre_any = soup.find('meta', attrs={'itemprop': 'genre'})
            if meta_genre_any and meta_genre_any.get('content'):
                content = meta_genre_any.get('content').strip()
                genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                return genres
            
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∂–∞–Ω—Ä–æ–≤: {e}")
            return []
    
    async def process_all_800_games(self, max_pages: int = 100):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –í–°–ï 800 –∏–≥—Ä"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –í–°–ï–• 800 –∏–≥—Ä —Å {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
        
        total_processed = 0
        
        for page in range(1, max_pages + 1):
            url = f"{self.base_url}/page/{page}/" if page > 1 else self.base_url
            
            logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}")
            html = await self.get_page(url)
            if not html:
                continue
            
            games = self.extract_games_from_page(html)
            if not games:
                logger.info(f"–ò–≥—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                continue
            
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ –∏–≥—Ä –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {len(games)}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∏–≥—Ä—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            for i, game in enumerate(games, 1):
                total_processed += 1
                logger.info(f"üéÆ [{total_processed}/800] {game['title']}")
                
                # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–≥—Ä—ã
                game_html = await self.get_page(game['url'])
                if game_html:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∂–∞–Ω—Ä—ã
                    genres = self.extract_genres_from_page(game_html, game['url'])
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result = {
                        'page': page,
                        'position_on_page': i,
                        'title': game['title'],
                        'url': game['url'],
                        'genres': genres,
                        'found_genres': len(genres) > 0
                    }
                    
                    self.all_games_with_genres.append(result)
                    
                    if genres:
                        genres_str = ", ".join(genres)
                        logger.info(f"‚úÖ {game['title']} -> {genres_str}")
                    else:
                        logger.warning(f"‚ùå {game['title']} -> –ñ–∞–Ω—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                await asyncio.sleep(0.2)
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
            await asyncio.sleep(1)
        
        logger.info(f"üéØ –í–°–ï–ì–û –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–≥—Ä: {total_processed}")
        return total_processed
    
    def display_all_results(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∫ –≤ Complete Genres"""
        logger.info("üéØ –ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö –í–°–ï–• 800 –ò–ì–† –° –ñ–ê–ù–†–ê–ú–ò:")
        logger.info("=" * 100)
        
        for i, game in enumerate(self.all_games_with_genres, 1):
            status = "‚úÖ" if game['found_genres'] else "‚ùå"
            genres_str = ", ".join(game['genres']) if game['genres'] else "–ù–ï –ù–ê–ô–î–ï–ù–û"
            
            logger.info(f"{status} [{i:3d}] –°—Ç—Ä.{game['page']:2d} –ü–æ–∑.{game['position_on_page']:2d} | {game['title']}")
            logger.info(f"     üîó {game['url']}")
            logger.info(f"     üè∑Ô∏è {genres_str}")
            logger.info("")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        with_genres = sum(1 for g in self.all_games_with_genres if g['found_genres'])
        without_genres = len(self.all_games_with_genres) - with_genres
        
        logger.info("=" * 100)
        logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"üéÆ –í—Å–µ–≥–æ –∏–≥—Ä: {len(self.all_games_with_genres)}")
        logger.info(f"‚úÖ –° –∂–∞–Ω—Ä–∞–º–∏: {with_genres}")
        logger.info(f"‚ùå –ë–µ–∑ –∂–∞–Ω—Ä–æ–≤: {without_genres}")
        logger.info(f"üìà –ü—Ä–æ—Ü–µ–Ω—Ç —Å –∂–∞–Ω—Ä–∞–º–∏: {(with_genres/len(self.all_games_with_genres)*100):.1f}%")
    
    def save_all_results(self, filename: str = "all_800_games_complete.json"):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.all_games_with_genres, f, ensure_ascii=False, indent=2)
        logger.info(f"üíæ –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
    
    def create_summary_report(self):
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç –ø–æ –∂–∞–Ω—Ä–∞–º"""
        genre_stats = {}
        
        for game in self.all_games_with_genres:
            if game['found_genres']:
                for genre in game['genres']:
                    if genre not in genre_stats:
                        genre_stats[genre] = []
                    genre_stats[genre].append(game['title'])
        
        logger.info("üéØ –û–¢–ß–ï–¢ –ü–û –ñ–ê–ù–†–ê–ú:")
        logger.info("=" * 80)
        
        for genre, games in sorted(genre_stats.items(), key=lambda x: len(x[1]), reverse=True):
            logger.info(f"üè∑Ô∏è {genre} ({len(games)} –∏–≥—Ä):")
            for game in games[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –∏–≥—Ä
                logger.info(f"   ‚Ä¢ {game}")
            if len(games) > 5:
                logger.info(f"   ... –∏ –µ—â–µ {len(games)-5} –∏–≥—Ä")
            logger.info("")
        
        logger.info(f"üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤: {len(genre_stats)}")

async def main():
    logger.info("üöÄ –ó–ê–ü–£–°–ö - –í–°–ï 800 –ò–ì–† –° –ñ–ê–ù–†–ê–ú–ò!")
    
    async with AllGamesExtractor() as extractor:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∏–≥—Ä—ã
        total = await extractor.process_all_800_games(max_pages=100)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        extractor.display_all_results()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        extractor.save_all_results()
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –ø–æ –∂–∞–Ω—Ä–∞–º
        extractor.create_summary_report()
        
        logger.info("üéâ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê! –í–°–ï 800 –ò–ì–† –û–ë–†–ê–ë–û–¢–ê–ù–´!")

if __name__ == "__main__":
    asyncio.run(main())
