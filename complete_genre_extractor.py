#!/usr/bin/env python3
"""
–ü–û–õ–ù–´–ô –°–ö–†–ò–ü–¢ –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –ñ–ê–ù–†–û–í:
1. –ù–∞–ø–æ–ª–Ω—è–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–≥—Ä–∞–º–∏
2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∂–∞–Ω—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∏–≥—Ä—ã
3. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–≥—Ä—ã - –∂–∞–Ω—Ä—ã
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import logging
import json
import sqlite3
import re
from datetime import datetime
from urllib.parse import urlparse, urljoin

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CompleteGenreExtractor:
    def __init__(self):
        self.base_url = "https://asst2game.ru"
        self.found_genres = {}  # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–≥—Ä—ã -> –∂–∞–Ω—Ä—ã
        self.session = None
        self.db_path = "games.db"
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        )
        await self.init_db()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS games (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL UNIQUE,
                    description TEXT,
                    rating TEXT,
                    genres TEXT,
                    image_url TEXT,
                    screenshots TEXT,
                    release_date TEXT,
                    url TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
    
    async def get_page(self, url: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logger.info(f"üåê –ó–∞–≥—Ä—É–∂–∞—é: {url}")
            async with self.session.get(url) as response:
                if response.status == 200:
                    content = await response.text()
                    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return content
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞: {response.status}")
                    return ""
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return ""
    
    def extract_games_from_page(self, html_content: str) -> list:
        """–ò–∑–≤–ª–µ—á—å –∏–≥—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            games = []
            
            # –ò—â–µ–º –≤—Å–µ —Å—Ç–∞—Ç—å–∏ —Å –∏–≥—Ä–∞–º–∏
            articles = soup.find_all('article')
            logger.info(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}")
            
            for article in articles:
                # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∏–≥—Ä—É
                link = article.find('a', href=True)
                if link:
                    href = link.get('href')
                    if href and href.endswith('.html'):
                        full_url = urljoin(self.base_url, href)
                        
                        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                        title_elem = article.find('h1') or article.find('h2') or article.find('h3') or link
                        title = title_elem.get_text().strip() if title_elem else ""
                        
                        if title and full_url:
                            games.append({
                                'title': title,
                                'url': full_url
                            })
            
            logger.info(f"üéÆ –ù–∞–π–¥–µ–Ω–æ –∏–≥—Ä –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(games)}")
            return games
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–≥—Ä: {e}")
            return []
    
    async def scrape_games(self, max_pages: int = 10):
        """–°–æ–±—Ä–∞—Ç—å –∏–≥—Ä—ã —Å —Å–∞–π—Ç–∞"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞—é —Å–±–æ—Ä –∏–≥—Ä (–º–∞–∫—Å–∏–º—É–º {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü)")
        
        all_games = []
        
        for page in range(1, max_pages + 1):
            url = f"{self.base_url}/page/{page}/" if page > 1 else self.base_url
            
            html = await self.get_page(url)
            if not html:
                continue
            
            games = self.extract_games_from_page(html)
            if not games:
                logger.info(f"‚ö†Ô∏è –ò–≥—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                break
            
            all_games.extend(games)
            logger.info(f"üìä –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: +{len(games)} –∏–≥—Ä, –≤—Å–µ–≥–æ: {len(all_games)}")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞
            await asyncio.sleep(1)
        
        logger.info(f"üéØ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –∏–≥—Ä: {len(all_games)}")
        return all_games
    
    def save_games_to_db(self, games: list):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–≥—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            saved = 0
            for game in games:
                try:
                    cursor.execute('''
                        INSERT OR IGNORE INTO games (title, url)
                        VALUES (?, ?)
                    ''', (game['title'], game['url']))
                    
                    if cursor.rowcount > 0:
                        saved += 1
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {game['title']}: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–≥—Ä –≤ –ë–î: {saved}")
            return saved
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
            return 0
    
    def extract_genres_from_page(self, html_content: str, url: str) -> list:
        """–ò–∑–≤–ª–µ—á—å –∂–∞–Ω—Ä—ã –ø–æ –¢–í–û–ï–ô –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: body > section.wrap.cf > section > div > div > article
            main_container = soup.select_one('body > section.wrap.cf > section > div > div > article')
            
            if main_container:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è {url}")
                
                # –ò—â–µ–º –º–µ—Ç–∞-—Ç–µ–≥ —Å –∂–∞–Ω—Ä–∞–º–∏
                meta_genre = main_container.find('meta', attrs={'itemprop': 'genre'})
                if meta_genre and meta_genre.get('content'):
                    content = meta_genre.get('content').strip()
                    logger.info(f"‚úÖ –ù–ê–ô–î–ï–ù–û: {content}")
                    
                    genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                    logger.info(f"‚úÖ –ñ–ê–ù–†–´: {genres}")
                    return genres
                else:
                    logger.warning(f"‚ö†Ô∏è –ú–µ—Ç–∞-—Ç–µ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ")
            else:
                logger.warning(f"‚ö†Ô∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {url}")
            
            # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            meta_genre_any = soup.find('meta', attrs={'itemprop': 'genre'})
            if meta_genre_any and meta_genre_any.get('content'):
                content = meta_genre_any.get('content').strip()
                logger.info(f"‚úÖ –ù–ê–ô–î–ï–ù–û –í –õ–Æ–ë–û–ú –ú–ï–°–¢–ï: {content}")
                genres = [genre.strip() for genre in content.split(',') if genre.strip()]
                return genres
            
            return []
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∂–∞–Ω—Ä–æ–≤: {e}")
            return []
    
    async def extract_genres_for_all_games(self):
        """–ò–∑–≤–ª–µ—á—å –∂–∞–Ω—Ä—ã –¥–ª—è –≤—Å–µ—Ö –∏–≥—Ä –∏–∑ –ë–î"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT id, title, url FROM games WHERE url IS NOT NULL")
            games = cursor.fetchall()
            conn.close()
            
            logger.info(f"üöÄ –ò–∑–≤–ª–µ–∫–∞—é –∂–∞–Ω—Ä—ã –¥–ª—è {len(games)} –∏–≥—Ä")
            
            for i, (game_id, title, url) in enumerate(games, 1):
                logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(games)}")
                
                html = await self.get_page(url)
                if html:
                    genres = self.extract_genres_from_page(html, url)
                    
                    if genres:
                        self.found_genres[title] = genres
                        logger.info(f"üéØ –†–ï–ó–£–õ–¨–¢–ê–¢: {title} -> {genres}")
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î
                        try:
                            conn = sqlite3.connect(self.db_path)
                            cursor = conn.cursor()
                            cursor.execute('''
                                UPDATE games SET genres = ? WHERE id = ?
                            ''', (json.dumps(genres, ensure_ascii=False), game_id))
                            conn.commit()
                            conn.close()
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î: {e}")
                    else:
                        logger.warning(f"‚ùå –ñ–∞–Ω—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {title}")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞
                if i % 5 == 0:
                    await asyncio.sleep(1)
            
            logger.info(f"üéØ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∂–∞–Ω—Ä–æ–≤: {len(self.found_genres)}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∂–∞–Ω—Ä–æ–≤: {e}")
    
    def display_results(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        logger.info("üéØ –ö–û–ù–ö–†–ï–¢–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´: –ù–∞–∑–≤–∞–Ω–∏–µ –∏–≥—Ä—ã - –∂–∞–Ω—Ä—ã")
        logger.info("=" * 80)
        
        for title, genres in self.found_genres.items():
            genres_str = ", ".join(genres)
            logger.info(f"üéÆ {title} - {genres_str}")
        
        logger.info("=" * 80)
        logger.info(f"üìä –í—Å–µ–≥–æ –∏–≥—Ä —Å –∂–∞–Ω—Ä–∞–º–∏: {len(self.found_genres)}")
    
    def save_results(self, filename: str = "complete_genres.json"):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.found_genres, f, ensure_ascii=False, indent=2)
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filename}")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –ñ–ê–ù–†–û–í")
    
    async with CompleteGenreExtractor() as extractor:
        # –®–∞–≥ 1: –°–æ–±–∏—Ä–∞–µ–º –∏–≥—Ä—ã
        games = await extractor.scrape_games(max_pages=100)  # –í–°–ï –°–¢–†–ê–ù–ò–¶–´ - –ü–û–õ–ù–´–ô –°–ë–û–†
        
        if games:
            # –®–∞–≥ 2: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            saved = extractor.save_games_to_db(games)
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–≥—Ä: {saved}")
            
            # –®–∞–≥ 3: –ò–∑–≤–ª–µ–∫–∞–µ–º –∂–∞–Ω—Ä—ã
            await extractor.extract_genres_for_all_games()
            
            # –®–∞–≥ 4: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ö–û–ù–ö–†–ï–¢–ù–´–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            extractor.display_results()
            
            # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω—è–µ–º
            extractor.save_results()
        
        logger.info("üéâ –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê! –ü–†–û–í–ï–†–¨ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–´–®–ï.")

if __name__ == "__main__":
    asyncio.run(main())
